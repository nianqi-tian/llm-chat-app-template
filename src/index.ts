/**
 * LLM Chat Application Template (æœ€ç»ˆä¿®æ­£ç‰ˆæœ¬ï¼šKVæŒä¹…åŒ–ã€æµå¼å…¼å®¹ã€è·¯ç”±)
 *
 * è§£å†³æµå¼ä¼ è¾“ã€IDç”Ÿæˆå’Œå†å²è®°å½•è¯»å–é—®é¢˜ã€‚
 * @license MIT
 */
import { v4 as uuidv4 } from 'uuid'; 
import { Env, ChatMessage, ConversationHistory, Message } from "./types";

// --- å…¨å±€çŠ¶æ€ï¼šç”¨äºå®ç°å–æ¶ˆåŠŸèƒ½ ---
const activeControllers = new Map<string, AbortController>(); 

// --- é…ç½®å¸¸é‡ ---
const MODEL_ID = "@cf/meta/llama-3.3-70b-instruct-fp8-fast"; 
const SYSTEM_PROMPT = "You are a helpful, friendly assistant. Provide concise and accurate responses.";

// --- è¾…åŠ©å‡½æ•°ï¼šKV å†å²è®°å½•ç®¡ç† ---

async function readHistory(env: Env, conversationId: string): Promise<ConversationHistory> {
    if (!conversationId) {
        return [];
    }
    
    try {
        // å°è¯•ä» KV è·å–æ•°æ®
        const historyJson = await env.CHAT_HISTORY.get(conversationId);
        
        if (historyJson) {
            // ç¡®ä¿è§£ææˆåŠŸï¼Œå¦‚æœå¤±è´¥ä¼šè¿›å…¥ catch å—
            return JSON.parse(historyJson) as ConversationHistory;
        }
        
    } catch (error) {
        // è®°å½• KV è¯»å–æˆ–è§£æå¤±è´¥çš„è¯¦ç»†é”™è¯¯ï¼Œè¿™é€šå¸¸æ˜¯å†å²è®°å½•ä¸æ˜¾ç¤ºçš„æ ¹æºä¹‹ä¸€
        console.error(`[KV ERROR] Read/Parse failed for ${conversationId}:`, error); 
    }
    return []; 
}


async function saveConversation(
    env: Env,
    conversationId: string,
    history: ConversationHistory 
): Promise<void> {
    try {
        const historyJsonString = JSON.stringify(history);
        await env.CHAT_HISTORY.put(conversationId, historyJsonString);
    } catch (error) {
        console.error(`[KV ERROR] Write failed for ${conversationId}:`, error);
    }
}

// --- API å¤„ç†å‡½æ•°ï¼šå†å²è®°å½•æå– ---

async function handleGetHistory(request: Request, env: Env): Promise<Response> {
    const url = new URL(request.url);
    const conversationId = url.searchParams.get('id'); 

    if (!conversationId) {
        return new Response(JSON.stringify({ error: "è¯·æ±‚ç¼ºå°‘ conversationId å‚æ•°" }), { 
            status: 400, 
            headers: { 'Content-Type': 'application/json' }
        });
    }

    try {
        const history = await readHistory(env, conversationId);

        return new Response(JSON.stringify({ 
            conversationId, 
            history 
        }), {
            headers: { 'Content-Type': 'application/json' },
            status: 200,
        });

    } catch (error) {
        console.error(`[API ERROR] Failed to retrieve history for ${conversationId}:`, error);
        return new Response(JSON.stringify({ error: "æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œæ— æ³•åŠ è½½å†å²è®°å½•" }), { 
            status: 500, 
            headers: { 'Content-Type': 'application/json' }
        });
    }
}


// --- API å¤„ç†å‡½æ•°ï¼šå–æ¶ˆè¯·æ±‚ ---

async function handlePostCancel(request: Request): Promise<Response> {
    const url = new URL(request.url);
    const pathSegments = url.pathname.split('/');
    const conversationId = pathSegments[pathSegments.length - 2]; 

    if (!conversationId) {
        return new Response('ç¼ºå°‘ conversationId', { status: 400 });
    }

    const controller = activeControllers.get(conversationId);
    
    if (controller) {
        controller.abort(); 
        activeControllers.delete(conversationId);
        
        console.log(`å¯¹è¯ ${conversationId} å·²æˆåŠŸè¢«ç”¨æˆ·å–æ¶ˆã€‚`);
        return new Response(JSON.stringify({ status: 'cancelled' }), {
            status: 200,
            headers: { 'Content-Type': 'application/json' },
        });
    } else {
        return new Response(JSON.stringify({ status: 'no active request found' }), {
            status: 404,
            headers: { 'Content-Type': 'application/json' },
        });
    }
}


// --- API å¤„ç†å‡½æ•°ï¼šæ ¸å¿ƒèŠå¤©é€»è¾‘ ---

async function handlePostChat(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
    try {
        const { messages: frontendMessages = [], conversationId: oldConversationId } = (await request.json()) as {
            messages: ChatMessage[]; 
            conversationId?: string; 
        };

        // ğŸš¨ ä¿®æ­£ï¼šç¡®ä¿åœ¨æ—§ ID ä¸º null æˆ– undefined æ—¶ï¼Œèƒ½æ­£ç¡®ç”Ÿæˆæ–° ID
        const conversationId = oldConversationId && oldConversationId !== 'null' ? oldConversationId : uuidv4(); 
        
        // 1. è®¾ç½® AbortController
        const controller = new AbortController();
        activeControllers.set(conversationId, controller);
        
        // 2. è¯»å–ä¸Šä¸‹æ–‡
        const history = await readHistory(env, conversationId);

        // 3. æ„å»ºå‘é€ç»™ AI çš„å®Œæ•´æ¶ˆæ¯åˆ—è¡¨ (çœç•¥æ„å»ºè¿‡ç¨‹ï¼Œå·²åœ¨ä¹‹å‰ä»£ç ä¸­å®ç°)
        const userMessageContent = frontendMessages[frontendMessages.length - 1].content;
        
        const userMessage: Message = {
            role: 'user',
            content: userMessageContent,
            timestamp: Date.now(),
        };

        let messagesForAI: ChatMessage[] = history.map(m => ({
            role: m.role,
            content: m.content
        } as ChatMessage));
        
        if (!messagesForAI.some((msg) => msg.role === "system")) {
            messagesForAI.unshift({ role: "system", content: SYSTEM_PROMPT });
        }
        messagesForAI.push(userMessage as ChatMessage);

        // 4. è°ƒç”¨ Workers AI
        const llmResponse = (await env.AI.run(
            MODEL_ID,
            {
                messages: messagesForAI,
                max_tokens: 1024,
            },
            {
                signal: controller.signal, 
                returnRawResponse: true,
            },
        )) as unknown as Response;

        if (!llmResponse.ok) {
            console.error("Workers AI åŸå§‹è°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç :", llmResponse.status);
            // å°è¯•è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç ´ç¢çš„æµ
            return new Response(JSON.stringify({ error: "LLM Provider Error" }), { status: 502, headers: { 'Content-Type': 'application/json' }});
        }

        // 5. æå–æµå¹¶è®¾ç½®æŒä¹…åŒ–é€»è¾‘
        let fullAiResponseContent = '';
        let isInterrupted = false;
        
        const [stream1, stream2] = llmResponse.body!.tee(); 

        ctx.waitUntil((async () => {
            try {
                const reader = stream1.getReader();
                const decoder = new TextDecoder();
                
                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;
                    
                    // ç¡®ä¿æˆ‘ä»¬æ”¶é›†çš„æ˜¯çº¯æ–‡æœ¬
                    fullAiResponseContent += decoder.decode(value);
                }
            } catch (error) {
                if (error instanceof DOMException && error.name === 'AbortError') {
                    isInterrupted = true;
                } else {
                    console.error("AI.run æµæ”¶é›†é”™è¯¯:", error);
                }
            } finally {
                // 6. æ¸…ç†å’ŒæŒä¹…åŒ–
                activeControllers.delete(conversationId); 
                
                const aiMessage: Message = {
                    role: 'assistant',
                    content: fullAiResponseContent,
                    timestamp: Date.now(),
                    interrupted: isInterrupted,
                };
                
                const updatedHistory = [...history, userMessage, aiMessage];
                await saveConversation(env, conversationId, updatedHistory); 
                console.log(`å¯¹è¯ ${conversationId} ä¿å­˜å®Œæˆã€‚`);
            }
        })());

        // 7. ç«‹å³è¿”å›æµå¼å“åº”
        const response = new Response(stream2, {
            status: llmResponse.status,
            headers: {
                ...llmResponse.headers,
                'Content-Type': 'text/event-stream', 
                'X-Conversation-ID': conversationId, // å…³é”®ï¼šè¿”å› ID ç»™å‰ç«¯
            },
        });
        return response;

    } catch (error) {
        console.error("Error processing chat request:", error);
        return new Response(
            JSON.stringify({ error: "Failed to process request" }),
            {
                status: 500,
                headers: { "content-type": "application/json" },
            },
        );
    }
}

// ... (export default { fetch(...) è·¯ç”±é€»è¾‘ä¿æŒä¸å˜) ...
export default {
    async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {
        const url = new URL(request.url);

        if (request.method === "OPTIONS") {
             const headers = {
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, POST, OPTIONS',
                'Access-Control-Allow-Headers': 'Content-Type, X-Conversation-ID',
                'Access-Control-Max-Age': '86400',
             };
             return new Response(null, { status: 204, headers });
        }

        if (url.pathname === "/" || !url.pathname.startsWith("/api/")) {
            return env.ASSETS.fetch(request);
        }

        if (url.pathname.startsWith("/api/history") && request.method === "GET") {
            return handleGetHistory(request, env);
        }

        if (request.method === 'POST' && url.pathname.match(/\/api\/chat\/[^/]+\/cancel$/)) {
             return handlePostCancel(request);
        }

        if (url.pathname === "/api/chat" && request.method === "POST") {
            return handlePostChat(request, env, ctx); 
        }

        return new Response("Not found", { status: 404 });
    },
} satisfies ExportedHandler<Env>;